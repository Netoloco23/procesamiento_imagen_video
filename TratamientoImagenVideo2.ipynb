{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6c56899e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cargando el detector de rostros y predictor de puntos de referencia faciales...\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from scipy.spatial import distance as dist\n",
    "import numpy as np\n",
    "import time\n",
    "import dlib\n",
    "import cv2\n",
    "from collections import OrderedDict\n",
    "\n",
    "# definir dos constantes, una para la proporcion de aspecto del ojo para indicar\n",
    "# parpadeo y luego una segunda constante para el número de\n",
    "# marcos el ojo debe estar por debajo del threshold\n",
    "EYE_AR_THRESH = 0.23\n",
    "EYE_AR_CONSEC_FRAMES = 35\n",
    "\n",
    "# inicializar los contadores de fotogramas y el número total de parpadeos\n",
    "COUNTER = 0\n",
    "\n",
    "# definir un diccionario que mapee los índices de la cara\n",
    "# puntos de referencia a regiones específicas de la cara\n",
    "FACIAL_LANDMARKS_IDXS = OrderedDict([\n",
    "    (\"mouth\", (48, 68)),\n",
    "    (\"right_eyebrow\", (17, 22)),\n",
    "    (\"left_eyebrow\", (22, 27)),\n",
    "    (\"right_eye\", (36, 42)),\n",
    "    (\"left_eye\", (42, 48)),\n",
    "    (\"nose\", (27, 35)),\n",
    "    (\"jaw\", (0, 17))\n",
    "])\n",
    "\n",
    "def eye_aspect_ratio(eye):\n",
    "    # calcular las distancias euclidianas entre los dos conjuntos de\n",
    "    # coordenadas verticales del ojo (x, y)\n",
    "    A = dist.euclidean(eye[1], eye[5])\n",
    "    B = dist.euclidean(eye[2], eye[4])\n",
    " \n",
    "    # calcular la distancia euclidiana entre la horizontal\n",
    "    # coordenadas del punto de referencia del ojo (x, y)\n",
    "    C = dist.euclidean(eye[0], eye[3])\n",
    " \n",
    "    # calcular la proporcion de aspecto del ojo\n",
    "    ear = (A + B) / (2.0 * C)\n",
    "    return ear\n",
    "\n",
    "def resize(img, width=None, height=None, interpolation=cv2.INTER_AREA):\n",
    "    global ratio\n",
    "    w, h, _ = img.shape\n",
    "\n",
    "    if width is None and height is None:\n",
    "        return img\n",
    "    elif width is None:\n",
    "        ratio = height / h\n",
    "        width = int(w * ratio)\n",
    "        resized = cv2.resize(img, (height, width), interpolation)\n",
    "        return resized\n",
    "    else:\n",
    "        ratio = width / w\n",
    "        height = int(h * ratio)\n",
    "        resized = cv2.resize(img, (height, width), interpolation)\n",
    "        return resized\n",
    "\n",
    "def shape_to_np(shape, dtype=\"int\"):\n",
    "    # inicializar la lista de coordenadas (x, y)\n",
    "    coords = np.zeros((68, 2), dtype=dtype)\n",
    "\n",
    "    # bucle sobre los 68 puntos de referencia faciales y convertirlos\n",
    "    # a una pareja de coordenadas (x, y)\n",
    "    for i in range(0, 68):\n",
    "        coords[i] = (shape.part(i).x, shape.part(i).y)\n",
    "\n",
    "    # devuelve la lista de coordenadas (x, y)\n",
    "    return coords\n",
    "\n",
    "camera = cv2.VideoCapture(0)\n",
    "\n",
    "predictor_path = 'shape_predictor_68_face_landmarks.dat'\n",
    "\n",
    "print('Cargando el detector de rostros y predictor de puntos de referencia faciales...')\n",
    "detector = dlib.get_frontal_face_detector()\n",
    "predictor = dlib.shape_predictor(predictor_path)\n",
    "\n",
    "# tomar los índices de los puntos de referencia faciales para la izquierda y\n",
    "# ojo derecho, respectivamente\n",
    "(lStart, lEnd) = FACIAL_LANDMARKS_IDXS[\"left_eye\"]\n",
    "(rStart, rEnd) = FACIAL_LANDMARKS_IDXS[\"right_eye\"]\n",
    "\n",
    "vs = cv2.VideoCapture(0)\n",
    "fileStream = True\n",
    "time.sleep(1.0)\n",
    "\n",
    "# bucle sobre los fotogramas del flujo de vídeo\n",
    "while True:\n",
    "    # tomar el fotograma del flujo de archivos de vídeo enhebrado, redimensionar\n",
    "    # y convertirlo en escala de grises\n",
    "    # canales)\n",
    "    ret, frame = camera.read()\n",
    "    if ret == False:\n",
    "        print('Error al capturar video de la camara. \\n')\n",
    "        break\n",
    "\n",
    "    frame_resized = resize(frame, width=240)\n",
    "    frame_gray = cv2.cvtColor(frame_resized, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # detectar rostros en el marco de la escala de grises\n",
    "    rects = detector(frame_gray, 0)\n",
    "    # bucle sobre las detecciones de caras\n",
    "    for rect in rects:\n",
    "        # determinar los puntos de referencia faciales para la región de la cara, entonces\n",
    "        # convertir las coordenadas del punto de referencia facial (x, y) en un NumPy\n",
    "        # arreglo\n",
    "        shape = predictor(frame_gray, rect)\n",
    "        shape = shape_to_np(shape)\n",
    " \n",
    "        # extraer las coordenadas del ojo izquierdo y derecho, y luego utilizar el\n",
    "        # coordenadas para calcular la proporcion de aspecto de ambos ojos\n",
    "        leftEye = shape[lStart:lEnd]\n",
    "        rightEye = shape[rStart:rEnd]\n",
    "        leftEAR = eye_aspect_ratio(leftEye)\n",
    "        rightEAR = eye_aspect_ratio(rightEye)\n",
    " \n",
    "        # tomar la proporcion de aspecto mínima del ojo\n",
    "        ear = min([leftEAR,rightEAR])\n",
    "\n",
    "        # comprobar si la proporcion de aspecto del ojo está por debajo del parpadeo\n",
    "        # threshold, y si es así, incrementa el contador de fotogramas de parpadeo\n",
    "        if ear < EYE_AR_THRESH:\n",
    "            COUNTER += 1\n",
    "\n",
    "            if 60 >= COUNTER >= EYE_AR_CONSEC_FRAMES:\n",
    "                cv2.putText(frame, \"Cuidado, la persona se esta quedando dormida!\", (10, 30),\n",
    "                            cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0, 255, 0), 2)\n",
    "\n",
    "            if COUNTER > 80:\n",
    "                cv2.putText(frame, \"La persona esta dormida\", (10, 30),\n",
    "                            cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0, 0, 255), 2)\n",
    "                \n",
    "        else:\n",
    "            # restablecer el contador de fotogramas del ojo\n",
    "            cv2.putText(frame, \"La persona esta despierta\", (10, 30),\n",
    "                            cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0, 0, 255), 2)\n",
    "            COUNTER = 0\n",
    "\n",
    "        for (x, y) in np.concatenate((leftEye, rightEye), axis=0):\n",
    "            cv2.circle(frame, (int(x / ratio), int(y / ratio)), 2, (255, 255, 255), -1)\n",
    "\n",
    "    # mostrar el marco\n",
    "    cv2.imshow(\"Frame\", frame)\n",
    "    key = cv2.waitKey(1) & 0xFF\n",
    " \n",
    "    # si se ha pulsado la tecla `q`, romper el bucle\n",
    "    if key == ord(\"q\"):\n",
    "        break\n",
    "\n",
    "cv2.destroyAllWindows()\n",
    "vs.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43123dae",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
